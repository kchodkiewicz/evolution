[1, 3, 5, 9, 10, 25, 34, 52, 61, 68]
Score: 0.8928571428571429 in 35 iterations
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.85      0.92      0.88        12

    accuracy                           0.89        28
   macro avg       0.89      0.90      0.89        28
weighted avg       0.90      0.89      0.89        28

Separate scores: [0.6428571428571429, 0.75, 0.8214285714285714, 0.6785714285714286, 0.7857142857142857, 0.7142857142857143, 0.9285714285714286, 0.6428571428571429, 0.6785714285714286, 0.6785714285714286]
Theoretical score: 0.8928571428571429
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.85      0.92      0.88        12

    accuracy                           0.89        28
   macro avg       0.89      0.90      0.89        28
weighted avg       0.90      0.89      0.89        28

[94mChosen classifiers:[0m
DecisionTreeClassifier(criterion='entropy')
DecisionTreeClassifier(splitter='random', criterion='entropy')
DecisionTreeClassifier(max_features='log2')
DecisionTreeClassifier(splitter='random', max_features='sqrt')
GaussianNB()
SGDClassifier(loss='log')
KNeighborsClassifier()
GaussianProcessClassifier(max_iter_predict=10)
LogisticRegression(solver='liblinear', penalty='l2')
PassiveAggressiveClassifier(C=10, loss='hinge', early_stopping=True)
