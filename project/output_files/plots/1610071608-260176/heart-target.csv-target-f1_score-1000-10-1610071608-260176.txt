[9, 11, 20, 25, 41, 47, 54, 59]
Score: 0.75 in 71 iterations
              precision    recall  f1-score   support

           0       0.73      0.67      0.70        12
           1       0.76      0.81      0.79        16

    accuracy                           0.75        28
   macro avg       0.75      0.74      0.74        28
weighted avg       0.75      0.75      0.75        28

Separate scores: [0.6785714285714286, 0.7142857142857143, 0.7142857142857143, 0.4642857142857143, 0.5, 0.4642857142857143, 0.6071428571428571, 0.6785714285714286]
Random committee (for comparison): 0.7142857142857143
              precision    recall  f1-score   support

           0       0.75      0.50      0.60        12
           1       0.70      0.88      0.78        16

    accuracy                           0.71        28
   macro avg       0.72      0.69      0.69        28
weighted avg       0.72      0.71      0.70        28


------------------------------------------
Chosen classifiers:
DecisionTreeClassifier(splitter='random', max_features='sqrt')
GaussianNB(var_smoothing=1)
SVC(kernel='sigmoid')
SGDClassifier(loss='log')
KNeighborsClassifier(algorithm='ball_tree', weights='distance')
GaussianProcessClassifier(n_restarts_optimizer=1, warm_start=True)
LogisticRegression()
LogisticRegression(solver='saga', penalty='none')
