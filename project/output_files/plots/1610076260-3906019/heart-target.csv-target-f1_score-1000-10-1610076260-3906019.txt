[6, 19, 20, 27, 36, 45, 46, 53, 57, 83]
Score: 0.75 in 32 iterations
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.68      0.93      0.79        14

    accuracy                           0.75        28
   macro avg       0.79      0.75      0.74        28
weighted avg       0.79      0.75      0.74        28

Separate scores: [0.6785714285714286, 0.8214285714285714, 0.7857142857142857, 0.8928571428571429, 0.7142857142857143, 0.7142857142857143, 0.6785714285714286, 0.7857142857142857, 0.75, 0.8214285714285714]
Random committee (for comparison): 0.8571428571428571
              precision    recall  f1-score   support

           0       1.00      0.71      0.83        14
           1       0.78      1.00      0.88        14

    accuracy                           0.86        28
   macro avg       0.89      0.86      0.85        28
weighted avg       0.89      0.86      0.85        28


------------------------------------------
[94mChosen classifiers:[0m
DecisionTreeClassifier(criterion='entropy', max_features='log2')
SVC(kernel='poly', gamma='auto')
SVC(kernel='sigmoid')
SGDClassifier(loss='squared_hinge')
KNeighborsClassifier(n_neighbors=10)
GaussianProcessClassifier(warm_start=True)
GaussianProcessClassifier(n_restarts_optimizer=1)
GaussianProcessClassifier(n_restarts_optimizer=5)
LogisticRegression(solver='newton-cg')
LinearDiscriminantAnalysis(solver='eigen', shrinkage=1.0)
