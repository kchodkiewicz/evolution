[5, 13, 14, 21, 31, 40, 55, 71, 74, 80]
Score: 0.75 in 29 iterations
              precision    recall  f1-score   support

           0       0.80      0.62      0.70        13
           1       0.72      0.87      0.79        15

    accuracy                           0.75        28
   macro avg       0.76      0.74      0.74        28
weighted avg       0.76      0.75      0.75        28

Separate scores: [0.7142857142857143, 0.8214285714285714, 0.6428571428571429, 0.6785714285714286, 0.8571428571428571, 0.7857142857142857, 0.75, 0.75, 0.75, 0.6785714285714286]
Random committee (for comparison): 0.7857142857142857
              precision    recall  f1-score   support

           0       0.89      0.62      0.73        13
           1       0.74      0.93      0.82        15

    accuracy                           0.79        28
   macro avg       0.81      0.77      0.78        28
weighted avg       0.81      0.79      0.78        28


------------------------------------------
Chosen classifiers:
DecisionTreeClassifier(max_features='log2')
GaussianNB(var_smoothing=1e9)
SVC()
SVC(kernel='sigmoid', gamma='auto')
SGDClassifier(loss='modified_huber', penalty='elasticnet')
KNeighborsClassifier(algorithm='brute')
LogisticRegression(penalty='none')
QuadraticDiscriminantAnalysis()
QuadraticDiscriminantAnalysis(tol=1.0e-1, store_covariance=True)
LinearDiscriminantAnalysis(solver='lsqr', shrinkage=1.0)
