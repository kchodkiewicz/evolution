[2, 10, 13, 34, 37, 44, 50, 59, 61, 66]
Score: 0.9262295081967213 in 38 iterations
              precision    recall  f1-score   support

          -1       0.92      0.98      0.95        57
           0       0.86      0.60      0.71        10
           1       0.94      0.93      0.94        55

    accuracy                           0.93       122
   macro avg       0.91      0.84      0.86       122
weighted avg       0.92      0.93      0.92       122

Separate scores: [0.8032786885245902, 0.9016393442622952, 0.9180327868852459, 0.9590163934426229, 0.9262295081967213, 0.9262295081967213, 0.9098360655737705, 0.9344262295081968, 0.9016393442622952, 0.9262295081967213]
Random committee (for comparison): 0.9180327868852459
              precision    recall  f1-score   support

          -1       0.90      0.98      0.94        57
           0       0.86      0.60      0.71        10
           1       0.94      0.91      0.93        55

    accuracy                           0.92       122
   macro avg       0.90      0.83      0.86       122
weighted avg       0.92      0.92      0.92       122


 ------------------------------------------ 
Chosen classifiers:
DecisionTreeClassifier(splitter='random')
GaussianNB()
GaussianNB(var_smoothing=1e9)
KNeighborsClassifier()
KNeighborsClassifier(weights='distance')
GaussianProcessClassifier()
GaussianProcessClassifier(n_restarts_optimizer=1, max_iter_predict=10)
LogisticRegression(solver='saga', penalty='none')
LogisticRegression(solver='liblinear', penalty='l2')
PassiveAggressiveClassifier(early_stopping=True)
