[1, 5, 6, 16, 17, 35, 37, 51, 59, 61]
Score: 0.9098360655737705 in 51 iterations
              precision    recall  f1-score   support

          -1       0.94      0.94      0.94        66
           0       0.83      0.62      0.71         8
           1       0.88      0.92      0.90        48

    accuracy                           0.91       122
   macro avg       0.88      0.83      0.85       122
weighted avg       0.91      0.91      0.91       122

Separate scores: [0.8360655737704918, 0.9344262295081968, 0.9098360655737705, 0.9180327868852459, 0.9098360655737705, 0.9672131147540983, 0.9180327868852459, 0.9098360655737705, 0.9180327868852459, 0.9426229508196722]
Theoretical score: 0.860655737704918
              precision    recall  f1-score   support

          -1       0.91      0.92      0.92        66
           0       1.00      0.12      0.22         8
           1       0.80      0.90      0.84        48

    accuracy                           0.86       122
   macro avg       0.90      0.65      0.66       122
weighted avg       0.87      0.86      0.84       122

[94mChosen classifiers:[0m
DecisionTreeClassifier(criterion='entropy')
DecisionTreeClassifier(max_features='log2')
DecisionTreeClassifier(criterion='entropy', max_features='log2')
SVC(C=1e-2)
SVC(C=1e2)
KNeighborsClassifier(n_neighbors=2)
KNeighborsClassifier(weights='distance')
GaussianProcessClassifier(n_restarts_optimizer=1, warm_start=True, max_iter_predict=10)
LogisticRegression(solver='saga', penalty='none')
LogisticRegression(solver='liblinear', penalty='l2')
