[11, 23, 25, 39, 51, 59, 66, 72]
Score: 0.8032786885245902 in 59 iterations
              precision    recall  f1-score   support

          -1       0.83      0.89      0.86        61
           0       1.00      0.14      0.25        14
           1       0.76      0.89      0.82        47

    accuracy                           0.80       122
   macro avg       0.86      0.64      0.64       122
weighted avg       0.82      0.80      0.77       122

Separate scores: [0.7704918032786885, 0.8688524590163934, 0.8688524590163934, 0.8442622950819673, 0.8360655737704918, 0.8278688524590164, 0.860655737704918, 0.8524590163934426]
Random committee (for comparison): 0.8524590163934426
              precision    recall  f1-score   support

          -1       0.84      0.89      0.86        61
           0       1.00      0.64      0.78        14
           1       0.84      0.87      0.85        47

    accuracy                           0.85       122
   macro avg       0.89      0.80      0.83       122
weighted avg       0.86      0.85      0.85       122


 ------------------------------------------ 
Chosen classifiers:
GaussianNB(var_smoothing=1)
SVC(kernel='linear')
SGDClassifier(loss='log')
KNeighborsClassifier(algorithm='kd_tree')
GaussianProcessClassifier(n_restarts_optimizer=1, warm_start=True, max_iter_predict=10)
LogisticRegression(solver='saga', penalty='none')
PassiveAggressiveClassifier(early_stopping=True)
QuadraticDiscriminantAnalysis(store_covariance=True)
